{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from keras import layers\n",
    "# from keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "tf.__version__\n",
    "tf.random.set_seed(123)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding data paths\n",
    "parent_dir = r'/mnt/E/datasets/pneumonia_kaggle'\n",
    "train_dir = os.path.join(parent_dir,'train')\n",
    "test_dir = os.path.join(parent_dir,'test')\n",
    "val_dir = os.path.join(parent_dir,'val')\n",
    "save_dir = r'/mnt/D/Projects/Pneumonia Kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 3495\n",
      "Pneumonia: 3495\n",
      "Difference: 0\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the data is balanced\n",
    "norm_train = os.listdir(os.path.join(train_dir, 'NORMAL'))\n",
    "pneu_train = os.listdir(os.path.join(train_dir, 'PNEUMONIA'))\n",
    "print(f\"Normal: {len(norm_train)}\")\n",
    "print(f\"Pneumonia: {len(pneu_train)}\")\n",
    "\n",
    "# The data is not balanced\n",
    "diff = len(pneu_train) - len(norm_train)\n",
    "print(f\"Difference: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do augmentation and write data to disk\n",
    "# It is only used if difference between classes > 1 image\n",
    "# This is to avoid repetition while enhancing the model\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "\n",
    "# Use counter to stop when the difference between classes is zero\n",
    "if diff > 1:\n",
    "    count = diff\n",
    "\n",
    "    norm_path = os.path.join(train_dir, 'NORMAL')\n",
    "\n",
    "    for im in norm_train:\n",
    "\n",
    "        if count > 0:\n",
    "            img = cv2.imread(os.path.join(norm_path, im))\n",
    "\n",
    "            rotated_1 = ndimage.rotate(img, 10)\n",
    "            cv2.imwrite(f\"{norm_path}/augmented_1_{im}\", rotated_1)\n",
    "\n",
    "            rotated_2 = ndimage.rotate(img, -10)\n",
    "            cv2.imwrite(f\"{norm_path}/augmented_2_{im}\", rotated_2)\n",
    "            count -= 2\n",
    "        \n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "batch_size = 32\n",
    "img_height = 450\n",
    "img_width = 450\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6990 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Converting data directory to a training set\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    labels='inferred',\n",
    "    color_mode='grayscale',\n",
    "    seed=123,\n",
    "    label_mode='binary',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 776 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Converting data directory to a validation set\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    shuffle=True,\n",
    "    labels='inferred',\n",
    "    color_mode='grayscale',\n",
    "    seed=123,\n",
    "    label_mode='binary',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Converting data directory to a test set\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    labels='inferred',\n",
    "    color_mode='grayscale',\n",
    "    seed=123,\n",
    "    label_mode='binary',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "# Getting class names\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(scale=1.0/255)\n",
    "train_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_ds = val_ds.map(lambda image,label:(rescale(image),label))\n",
    "test_ds  = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Structuring the model\n",
    "num_classes = len(class_names)\n",
    "\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=1, verbose=1, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ModelCheckpoint(f\"{save_dir}/pneumonia_{epochs}e_binary_gray.h5\")]\n",
    "model = keras.models.Sequential()\n",
    "# model.add(layers.experimental.preprocessing.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(32,3, activation='relu', input_shape=(img_width,img_height,1)))\n",
    "model.add(layers.MaxPool2D())\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(32,3,activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "# model.add(layers.Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "              optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 1491s 7s/step - loss: 0.1725 - accuracy: 0.9309 - val_loss: 0.1102 - val_accuracy: 0.9639\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1434s 7s/step - loss: 0.0600 - accuracy: 0.9754 - val_loss: 0.1667 - val_accuracy: 0.9343\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1452s 7s/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 0.1022 - val_accuracy: 0.9716\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1416s 6s/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 0.1198 - val_accuracy: 0.9549\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1445s 7s/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.0942 - val_accuracy: 0.9742\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1428s 7s/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.2629 - val_accuracy: 0.9278\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1422s 6s/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.1688 - val_accuracy: 0.9639\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1411s 6s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 4.6450e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 8.\n",
      "219/219 [==============================] - 1411s 6s/step - loss: 4.6450e-04 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9678\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history = model.fit(\n",
    "                    train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 448, 448, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 224, 224, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 222, 222, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 394272)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                25233472  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,243,105\n",
      "Trainable params: 25,243,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model.save(f\"{save_dir}/pneumonia_{epochs}e_binary_gray.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(f\"{save_dir}/pneumonia_{epochs}e_binary_gray.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Getting x and y from the test set\n",
    "test_preds = []\n",
    "y_test = []\n",
    "for x,y in test_ds:\n",
    "    test_pred = model.predict(x)\n",
    "    # x_test.append(x)\n",
    "    # y_test.append(y)\n",
    "    test_preds.extend(test_pred)\n",
    "    y_test.extend(y)\n",
    "\n",
    "preds = np.array(test_preds)\n",
    "y_pred = np.where(preds > 0.5, 1, 0)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model is 1.00\n",
      "Precision of the model is 0.71\n",
      "F1-score of the model is 0.83\n"
     ]
    }
   ],
   "source": [
    "# Assessing model performance using confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm  = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*((precision * recall)/(precision + recall))\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "print(\"F1-score of the model is {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 450, 1)\n",
      "(1, 450, 450, 1)\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "[1.]\n",
      "[1]\n",
      "This image is 0.00 percent normal and 100.00 percent pneumonia.\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "# E:\\Downloads\\chest pneumonia.jpg\n",
    "img = keras.preprocessing.image.load_img(r\"/mnt/E/datasets/pneumonia_kaggle/test/PNEUMONIA/person1_virus_6.jpeg\",\n",
    "                                         target_size=(img_width, img_height),\n",
    "                                         color_mode='grayscale')\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "print(img_array.shape)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "print(img_array.shape)\n",
    "predictions = model.predict(img_array)\n",
    "score = predictions[0]\n",
    "print(score)\n",
    "tmp_pred = np.where(score > 0.5, 1, 0)\n",
    "print(tmp_pred)\n",
    "print(\"This image is %.2f percent normal and %.2f percent pneumonia.\" % (100 * (1 - score), 100 * score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
